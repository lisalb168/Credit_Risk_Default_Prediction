{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [Import and downsampling data](#Import-and-downsampling-data)\n",
    "* [Function to log results](#Function-to-log-results)\n",
    "* [Modeling](#Modeling)\n",
    "    * [1. Random Forest](#1.-Random-Forest)\n",
    "    * [2. XGboost](#2.-XGboost )\n",
    "    * [3. LightGBM](#3.-LightGBM)\n",
    "    * [4. Logistic Regression with regularizations](#4.-Logistic-Regression-with-regularizations)\n",
    "    * [5. KNN](#5.-KNN)      \n",
    "    * [6. SVM](#6.-SVM)\n",
    "* [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} -c conda-forge lightgbm\n",
    "#!pip install xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import csv\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "#from sklearn.metrics import plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and downsampling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to create a balanced training dataset to be used by all ML models that we build shortly. Test sets are still imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_all = pd.read_csv('sm_data.csv')\n",
    "X = data_all.iloc[:,1:]\n",
    "y = data_all['TARGET']\n",
    "\n",
    "# train test split using test_size = 0.2 \n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "X_train_0 = X_train.loc[y_train == 0,:].copy().sample(frac = 0.09)\n",
    "X_train_1 = X_train.loc[y_train == 1,:].copy()\n",
    "\n",
    "X_train_0['target'] = 0\n",
    "X_train_1['target'] = 1\n",
    "\n",
    "# use frac = 1 to randomize the rows\n",
    "X_train_new = X_train_0.append(X_train_1).sample(frac = 1)\n",
    "\n",
    "X_train_new_x = X_train_new.drop(columns='target')\n",
    "y_train_new = X_train_new['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (40209, 350)\n",
      "y train shape:  (40209,)\n",
      "X test shape:  (61501, 350)\n",
      "y test shape:  (61501,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train shape: \", X_train_new_x.shape)\n",
    "print(\"y train shape: \", y_train_new.shape)\n",
    "print(\"X test shape: \", X_test.shape)\n",
    "print(\"y test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save X_train_new_x, y_train_new, X_test and y_test for future model evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new_x.to_csv(\"X_train_new_x.csv\", index=False)\n",
    "y_train_new.to_csv(\"y_train_new.csv\", index=False)\n",
    "X_test.to_csv(\"X_test.csv\", index=False)\n",
    "y_test.to_csv(\"y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:  Train: [    0     2     3 ... 40206 40207 40208] Validation: [    1    15    19 ... 40184 40193 40197]\n",
      "Fold 2:  Train: [    0     1     2 ... 40205 40206 40208] Validation: [    8    12    21 ... 40203 40204 40207]\n",
      "Fold 3:  Train: [    0     1     2 ... 40206 40207 40208] Validation: [    3     9    10 ... 40198 40201 40202]\n",
      "Fold 4:  Train: [    0     1     3 ... 40205 40206 40207] Validation: [    2     5     6 ... 40196 40199 40208]\n",
      "Fold 5:  Train: [    1     2     3 ... 40204 40207 40208] Validation: [    0     4    13 ... 40187 40205 40206]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "kf.get_n_splits(X_train_new_x)\n",
    "\n",
    "i = 1\n",
    "for train_index, val_index in kf.split(X_train_new_x):\n",
    "    print(f\"Fold {i}: \", \"Train:\", train_index, \"Validation:\", val_index)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_log(cv_clf, modelname):\n",
    "    rlt_dict = {}\n",
    "\n",
    "    rlt_dict['best_estimator_'] = [cv_clf.best_estimator_]\n",
    "    rlt_dict['best_params_'] = [cv_clf.best_params_]\n",
    "    rlt_dict['best_score_'] = [cv_clf.best_score_]\n",
    "    rlt_dict['best_index_'] = [cv_clf.best_index_]\n",
    "\n",
    "    rlt_dict['candidate_params'] = [cv_clf.cv_results_['params']]\n",
    "    rlt_dict['mean_test_score'] = [cv_clf.cv_results_['mean_test_score']]\n",
    "    rlt_dict['std_test_score'] = [cv_clf.cv_results_['std_test_score']]\n",
    "    rlt_dict['mean_train_score'] = [cv_clf.cv_results_['mean_train_score']]\n",
    "    rlt_dict['std_train_score'] = [cv_clf.cv_results_['std_train_score']]\n",
    "\n",
    "    rlt_dict['split0_test_score'] = [cv_clf.cv_results_['split0_test_score']]\n",
    "    rlt_dict['split1_test_score'] = [cv_clf.cv_results_['split1_test_score']]\n",
    "    rlt_dict['split2_test_score'] = [cv_clf.cv_results_['split2_test_score']]\n",
    "    rlt_dict['split3_test_score'] = [cv_clf.cv_results_['split3_test_score']]\n",
    "    rlt_dict['split4_test_score'] = [cv_clf.cv_results_['split4_test_score']]\n",
    "\n",
    "    rlt_dict['split0_train_score'] = [cv_clf.cv_results_['split0_train_score']]\n",
    "    rlt_dict['split1_train_score'] = [cv_clf.cv_results_['split1_train_score']]\n",
    "    rlt_dict['split2_train_score'] = [cv_clf.cv_results_['split2_train_score']]\n",
    "    rlt_dict['split3_train_score'] = [cv_clf.cv_results_['split3_train_score']]\n",
    "    rlt_dict['split4_train_score'] = [cv_clf.cv_results_['split4_train_score']]\n",
    "    \n",
    "    rlt_dict['std_of_best_mean_test_score'] = [cv_clf.cv_results_['std_test_score'][max(enumerate(cv_clf.cv_results_['mean_test_score']),key=(lambda x: x[1]))[0]]]\n",
    "\n",
    "    rlt_df = pd.DataFrame.from_dict(rlt_dict)\n",
    "    \n",
    "    filename = modelname + '_' + 'cv_rlt.csv'\n",
    "    rlt_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 3 models we build are tree based. Since tree based models are robust regardless of the skewed distributions of the features, we do not need to scale the features. Later on when we train other classification models that are more sensitive to the scale of features, such as logistic regression, KNN and SVM, we first transform some of the features before fitting the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.process_time()\n",
    "\n",
    "#when max depth is large (eg. 20), it's obvious that the RF model is overfitting \n",
    "#(CV training score 97%, test score 66%)\n",
    "\n",
    "niter, verbose, random_state = [5, 0, 123] \n",
    "param_space = {'n_estimators': range(100,500,100), 'max_depth': range(1,10)} \n",
    "\n",
    "clf = RandomForestClassifier(random_state=random_state)\n",
    "cv_clf = RandomizedSearchCV(clf, param_space, cv=kf, n_iter=niter, scoring='roc_auc', return_train_score=True, \n",
    "                            verbose=verbose, n_jobs=-1) \n",
    "cv_clf.fit(X_train_new_x, y_train_new)\n",
    "\n",
    "print('completed in {} s'.format(time.process_time() - start))\n",
    "\n",
    "# write out results\n",
    "model_log(cv_clf, 'randomforest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Five candidate parameters are:  [{'n_estimators': 100, 'max_depth': 5}, {'n_estimators': 400, 'max_depth': 4}, {'n_estimators': 400, 'max_depth': 8}, {'n_estimators': 100, 'max_depth': 8}, {'n_estimators': 400, 'max_depth': 9}]\n",
      "2. Best number of trees and depth are: 400 and 9\n",
      "3. Best average CV validation score is:  0.7499708327404105\n",
      "4. Standard Deviation of Best average CV validation score is:  0.007575448338780573\n",
      "5. Average CV validation score:  [0.73404878 0.73197666 0.74795543 0.74571211 0.74997083]\n",
      "6. Standard Deviation of CV validation score:  [0.00770114 0.00750812 0.00733293 0.00707123 0.00757545]\n",
      "7. Average CV training score:  [0.75566938 0.74596377 0.82225717 0.8197234  0.85312945]\n",
      "8. Standard Deviation of CV training score:  [0.00226952 0.00211268 0.00089419 0.00108859 0.00083326]\n",
      "1st fold validation score:  [0.74598698 0.74386643 0.76052436 0.75719985 0.76300074]\n",
      "2nd fold validation score:  [0.72379893 0.72182914 0.73822735 0.73587173 0.7399635 ]\n",
      "3rd fold validation score:  [0.72788531 0.72690429 0.74400614 0.7415484  0.74594128]\n",
      "4th fold validation score:  [0.73559807 0.73187553 0.74862733 0.74756253 0.75083517]\n",
      "5th fold validation score:  [0.73697498 0.73540831 0.74839203 0.74637815 0.75011351]\n",
      "1st fold training score:  [0.75273006 0.74298164 0.82141038 0.81836916 0.85275103]\n",
      "2nd fold training score:  [0.75764559 0.7476665  0.82309438 0.82111357 0.85376603]\n",
      "3rd fold training score:  [0.75396672 0.74557803 0.8225944  0.82000609 0.85345382]\n",
      "4th fold training score:  [0.75516428 0.74467625 0.82099507 0.81855714 0.85168746]\n",
      "5th fold training score:  [0.75884026 0.74891642 0.82319164 0.82057106 0.85398889]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "result = pd.read_csv('randomforest_cv_rlt.csv')\n",
    "candidate_params = ast.literal_eval(result.candidate_params.values[0])\n",
    "print(\"1. Five candidate parameters are: \", candidate_params)\n",
    "best_n = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['n_estimators']\n",
    "best_d = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['max_depth']\n",
    "print(\"2. Best number of trees and depth are: {} and {}\".format(best_n, best_d))\n",
    "best_score = result.best_score_.values[0]\n",
    "print(\"3. Best average CV validation score is: \", best_score)\n",
    "std_of_best_score = result.std_of_best_mean_test_score.values[0]\n",
    "print(\"4. Standard Deviation of Best average CV validation score is: \", std_of_best_score)\n",
    "mean_test_score = result.mean_test_score.values[0]\n",
    "print(\"5. Average CV validation score: \", mean_test_score)\n",
    "std_test_score = result.std_test_score.values[0]\n",
    "print(\"6. Standard Deviation of CV validation score: \", std_test_score)\n",
    "mean_train_score = result.mean_train_score.values[0]\n",
    "print(\"7. Average CV training score: \", mean_train_score)\n",
    "std_train_score = result.std_train_score.values[0]\n",
    "print(\"8. Standard Deviation of CV training score: \", std_train_score)\n",
    "\n",
    "print(\"1st fold validation score: \", result.split0_test_score.values[0])\n",
    "print(\"2nd fold validation score: \", result.split1_test_score.values[0])\n",
    "print(\"3rd fold validation score: \", result.split2_test_score.values[0])\n",
    "print(\"4th fold validation score: \", result.split3_test_score.values[0])\n",
    "print(\"5th fold validation score: \", result.split4_test_score.values[0])\n",
    "print(\"1st fold training score: \", result.split0_train_score.values[0])\n",
    "print(\"2nd fold training score: \", result.split1_train_score.values[0])\n",
    "print(\"3rd fold training score: \", result.split2_train_score.values[0])\n",
    "print(\"4th fold training score: \", result.split3_train_score.values[0])\n",
    "print(\"5th fold training score: \", result.split4_train_score.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XGboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.process_time()\n",
    "\n",
    "niter, verbose, random_state = [5, 0, 123] \n",
    "param_space = {'n_estimators': range(100,500,100), 'learning_rate': [0.01,0.1,0.5], \n",
    "               'max_depth': range(1,10), 'gamma': [0.001,0.01,1,10]}\n",
    "               \n",
    "clf = XGBClassifier(objective='binary:logistic', verbosity=verbose, booster='gbtree', tree_method='auto', \n",
    "                            subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, \n",
    "                            reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=random_state)\n",
    "cv_clf = RandomizedSearchCV(clf, param_space, cv=kf, n_iter=niter, scoring='roc_auc', return_train_score=True, \n",
    "                            verbose=verbose, n_jobs=-1)\n",
    "cv_clf.fit(X_train_new_x, y_train_new)\n",
    "\n",
    "print('completed in {} s'.format(time.process_time() - start))\n",
    "\n",
    "# write out results\n",
    "model_log(cv_clf, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Five candidate parameters are:  [{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.001}, {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.01, 'gamma': 10}, {'n_estimators': 200, 'max_depth': 2, 'learning_rate': 0.01, 'gamma': 0.001}, {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.5, 'gamma': 0.001}, {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 10}]\n",
      "2. Best number of trees, learning rate, depth and gamma are: 200, 0.1, 5 and 0.001\n",
      "3. Best average CV validation score is:  0.7722415850612538\n",
      "4. Standard Deviation of Best average CV validation score is:  0.007403126618375358\n",
      "5. Average CV validation score:  [0.77224159 0.76618283 0.72106212 0.74706994 0.73872224]\n",
      "6. Standard Deviation of CV validation score:  [0.00740313 0.00762454 0.00702354 0.00595042 0.00797753]\n",
      "7. Average CV training score:  [0.88045    0.86465668 0.72665755 0.93424846 0.75471596]\n",
      "8. Standard Deviation of CV training score:  [0.00189341 0.0006524  0.00173858 0.00064797 0.00152326]\n",
      "1st fold validation score:  [0.78573584 0.77748715 0.72782278 0.75643577 0.74866969]\n",
      "2nd fold validation score:  [0.76396555 0.75674914 0.71252469 0.73892171 0.72792349]\n",
      "3rd fold validation score:  [0.76767814 0.76197397 0.72156267 0.74321941 0.73823247]\n",
      "4th fold validation score:  [0.77300906 0.77252054 0.72966825 0.74990761 0.74651625]\n",
      "5th fold validation score:  [0.77081916 0.76218286 0.71373129 0.74686518 0.73226847]\n",
      "1st fold training score:  [0.87997635 0.86486446 0.72418019 0.93341973 0.75192197]\n",
      "2nd fold training score:  [0.88059307 0.86568951 0.72938889 0.93391086 0.75653793]\n",
      "3rd fold training score:  [0.88235623 0.86427029 0.72708377 0.93534678 0.75478757]\n",
      "4th fold training score:  [0.87713184 0.86372754 0.72557489 0.93449454 0.75498561]\n",
      "5th fold training score:  [0.88219253 0.86473161 0.72706001 0.93407038 0.75534671]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "result = pd.read_csv('xgboost_cv_rlt.csv')\n",
    "candidate_params = ast.literal_eval(result.candidate_params.values[0])\n",
    "print(\"1. Five candidate parameters are: \", candidate_params)\n",
    "best_n = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['n_estimators']\n",
    "best_d = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['max_depth']\n",
    "best_lr = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['learning_rate']\n",
    "best_gamma = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['gamma']\n",
    "print(\"2. Best number of trees, learning rate, depth and gamma are: {}, {}, {} and {}\".format(best_n, best_lr, best_d, best_gamma))\n",
    "best_score = result.best_score_.values[0]\n",
    "print(\"3. Best average CV validation score is: \", best_score)\n",
    "std_of_best_score = result.std_of_best_mean_test_score.values[0]\n",
    "print(\"4. Standard Deviation of Best average CV validation score is: \", std_of_best_score)\n",
    "mean_test_score = result.mean_test_score.values[0]\n",
    "print(\"5. Average CV validation score: \", mean_test_score)\n",
    "std_test_score = result.std_test_score.values[0]\n",
    "print(\"6. Standard Deviation of CV validation score: \", std_test_score)\n",
    "mean_train_score = result.mean_train_score.values[0]\n",
    "print(\"7. Average CV training score: \", mean_train_score)\n",
    "std_train_score = result.std_train_score.values[0]\n",
    "print(\"8. Standard Deviation of CV training score: \", std_train_score)\n",
    "\n",
    "print(\"1st fold validation score: \", result.split0_test_score.values[0])\n",
    "print(\"2nd fold validation score: \", result.split1_test_score.values[0])\n",
    "print(\"3rd fold validation score: \", result.split2_test_score.values[0])\n",
    "print(\"4th fold validation score: \", result.split3_test_score.values[0])\n",
    "print(\"5th fold validation score: \", result.split4_test_score.values[0])\n",
    "print(\"1st fold training score: \", result.split0_train_score.values[0])\n",
    "print(\"2nd fold training score: \", result.split1_train_score.values[0])\n",
    "print(\"3rd fold training score: \", result.split2_train_score.values[0])\n",
    "print(\"4th fold training score: \", result.split3_train_score.values[0])\n",
    "print(\"5th fold training score: \", result.split4_train_score.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.process_time()\n",
    "\n",
    "niter, verbose, random_state = [5, 0, 123] \n",
    "param_space = {'n_estimators': range(100,500,100), 'learning_rate': [0.01,0.1,0.5], \n",
    "               'max_depth': range(1,5)}\n",
    "\n",
    "clf = LGBMClassifier(colsample_bytree=1, subsample=1, reg_alpha=0, reg_lambda=1, verbose=verbose)\n",
    "cv_clf = RandomizedSearchCV(clf, param_space, cv=kf, n_iter=niter, scoring='roc_auc', return_train_score=True, \n",
    "                            verbose=verbose, n_jobs = -1)  \n",
    "cv_clf.fit(X_train_new_x, y_train_new)\n",
    "\n",
    "print('completed in {} s'.format(time.process_time() - start))\n",
    "\n",
    "# write out results\n",
    "model_log(cv_clf, 'lightgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Five candidate parameters are:  [{'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.5}, {'n_estimators': 200, 'max_depth': 2, 'learning_rate': 0.1}, {'n_estimators': 300, 'max_depth': 1, 'learning_rate': 0.5}, {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.5}, {'n_estimators': 400, 'max_depth': 1, 'learning_rate': 0.5}]\n",
      "2. Best number of trees, learning rate and depth are: 400, 0.5 and 1\n",
      "3. Best average CV validation score is:  0.7703665520630054\n",
      "4. Standard Deviation of Best average CV validation score is:  0.006516696411119587\n",
      "5. Average CV validation score:  [0.76875892 0.76774851 0.76936503 0.75036595 0.77036655]\n",
      "6. Standard Deviation of CV validation score:  [0.00729377 0.00597662 0.00626044 0.00461198 0.0065167 ]\n",
      "7. Average CV training score:  [0.7985437  0.78386748 0.78580417 0.92184532 0.78923898]\n",
      "8. Standard Deviation of CV training score:  [0.0014364  0.00158614 0.00161512 0.00126126 0.00166479]\n",
      "1st fold validation score:  [0.78130973 0.77719603 0.78014901 0.75553172 0.78142972]\n",
      "2nd fold validation score:  [0.75995502 0.76009807 0.76268095 0.74380313 0.76316894]\n",
      "3rd fold validation score:  [0.7640625  0.76435143 0.76401234 0.74959462 0.7648287 ]\n",
      "4th fold validation score:  [0.77128909 0.77154768 0.77165771 0.74734865 0.77294424]\n",
      "5th fold validation score:  [0.76717805 0.76554909 0.768325   0.75555226 0.76946105]\n",
      "1st fold training score:  [0.79595382 0.781268   0.78301728 0.92027289 0.78640635]\n",
      "2nd fold training score:  [0.80027007 0.78555081 0.7875994  0.92197321 0.7911194 ]\n",
      "3rd fold training score:  [0.7993239  0.78523855 0.78720671 0.92299288 0.79070943]\n",
      "4th fold training score:  [0.79867559 0.78293114 0.78556774 0.92056132 0.78900519]\n",
      "5th fold training score:  [0.79849512 0.78434892 0.78562974 0.9234263  0.78895454]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "result = pd.read_csv('lightgbm_cv_rlt.csv')\n",
    "candidate_params = ast.literal_eval(result.candidate_params.values[0])\n",
    "print(\"1. Five candidate parameters are: \", candidate_params)\n",
    "best_n = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['n_estimators']\n",
    "best_d = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['max_depth']\n",
    "best_lr = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['learning_rate']\n",
    "print(\"2. Best number of trees, learning rate and depth are: {}, {} and {}\".format(best_n, best_lr, best_d))\n",
    "best_score = result.best_score_.values[0]\n",
    "print(\"3. Best average CV validation score is: \", best_score)\n",
    "std_of_best_score = result.std_of_best_mean_test_score.values[0]\n",
    "print(\"4. Standard Deviation of Best average CV validation score is: \", std_of_best_score)\n",
    "mean_test_score = result.mean_test_score.values[0]\n",
    "print(\"5. Average CV validation score: \", mean_test_score)\n",
    "std_test_score = result.std_test_score.values[0]\n",
    "print(\"6. Standard Deviation of CV validation score: \", std_test_score)\n",
    "mean_train_score = result.mean_train_score.values[0]\n",
    "print(\"7. Average CV training score: \", mean_train_score)\n",
    "std_train_score = result.std_train_score.values[0]\n",
    "print(\"8. Standard Deviation of CV training score: \", std_train_score)\n",
    "\n",
    "print(\"1st fold validation score: \", result.split0_test_score.values[0])\n",
    "print(\"2nd fold validation score: \", result.split1_test_score.values[0])\n",
    "print(\"3rd fold validation score: \", result.split2_test_score.values[0])\n",
    "print(\"4th fold validation score: \", result.split3_test_score.values[0])\n",
    "print(\"5th fold validation score: \", result.split4_test_score.values[0])\n",
    "print(\"1st fold training score: \", result.split0_train_score.values[0])\n",
    "print(\"2nd fold training score: \", result.split1_train_score.values[0])\n",
    "print(\"3rd fold training score: \", result.split2_train_score.values[0])\n",
    "print(\"4th fold training score: \", result.split3_train_score.values[0])\n",
    "print(\"5th fold training score: \", result.split4_train_score.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression with regularizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.process_time()\n",
    "\n",
    "niter, verbose, random_state = [5, 0, 123] \n",
    "param_space = {'penalty': ['l1','l2'], 'C': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1, 1, 10, 100]}\n",
    "        \n",
    "clf = LogisticRegression(random_state=random_state)\n",
    "cv_clf = RandomizedSearchCV(clf, param_space, cv=kf, n_iter=niter, scoring='roc_auc', return_train_score=True, \n",
    "                            verbose=verbose, n_jobs = -1) \n",
    "cv_clf.fit(X_train_new_x, y_train_new)\n",
    "\n",
    "print('completed in {} s'.format(time.process_time() - start))\n",
    "\n",
    "# write out results\n",
    "model_log(cv_clf, 'logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Five candidate parameters are:  [{'penalty': 'l1', 'C': 100}, {'penalty': 'l2', 'C': 0.001}, {'penalty': 'l2', 'C': 100}, {'penalty': 'l2', 'C': 0.005}, {'penalty': 'l2', 'C': 0.1}]\n",
      "2. Best C and penalty are: 100 and l1\n",
      "3. Best average CV validation score is:  0.7652214570941079\n",
      "4. Standard Deviation of Best average CV validation score is:  0.003987849080163703\n",
      "5. Average CV validation score:  [0.76522146 0.66303347 0.66356286 0.66162847 0.66300642]\n",
      "6. Standard Deviation of CV validation score:  [0.00398785 0.00695754 0.00434593 0.0055261  0.00776671]\n",
      "7. Average CV training score:  [0.77381036 0.66467191 0.66526745 0.6631809  0.6645457 ]\n",
      "8. Standard Deviation of CV training score:  [0.00100667 0.00239779 0.00441104 0.00189288 0.00219546]\n",
      "1st fold validation score:  [0.75939492 0.65572886 0.65939621 0.65401359 0.65451265]\n",
      "2nd fold validation score:  [0.7649992  0.66580904 0.6709678  0.66900502 0.67202593]\n",
      "3rd fold validation score:  [0.76626005 0.67422651 0.665995   0.66627048 0.67255597]\n",
      "4th fold validation score:  [0.77171935 0.66379259 0.66037689 0.66155249 0.65972232]\n",
      "5th fold validation score:  [0.76373359 0.65560945 0.66107811 0.65730023 0.65621438]\n",
      "1st fold training score:  [0.77531322 0.6666065  0.67091613 0.66473626 0.66522791]\n",
      "2nd fold training score:  [0.77432012 0.66122571 0.66602013 0.66438678 0.66728886]\n",
      "3rd fold training score:  [0.77304704 0.66787253 0.65911569 0.65982426 0.66591732]\n",
      "4th fold training score:  [0.77241582 0.66468108 0.66147271 0.66233901 0.66098039]\n",
      "5th fold training score:  [0.77395559 0.66297371 0.66881258 0.66461819 0.663314  ]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "result = pd.read_csv('logistic_cv_rlt.csv')\n",
    "candidate_params = ast.literal_eval(result.candidate_params.values[0])\n",
    "print(\"1. Five candidate parameters are: \", candidate_params)\n",
    "best_c = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['C']\n",
    "best_penalty = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['penalty']\n",
    "print(\"2. Best C and penalty are: {} and {}\".format(best_c, best_penalty))\n",
    "best_score = result.best_score_.values[0]\n",
    "print(\"3. Best average CV validation score is: \", best_score)\n",
    "std_of_best_score = result.std_of_best_mean_test_score.values[0]\n",
    "print(\"4. Standard Deviation of Best average CV validation score is: \", std_of_best_score)\n",
    "mean_test_score = result.mean_test_score.values[0]\n",
    "print(\"5. Average CV validation score: \", mean_test_score)\n",
    "std_test_score = result.std_test_score.values[0]\n",
    "print(\"6. Standard Deviation of CV validation score: \", std_test_score)\n",
    "mean_train_score = result.mean_train_score.values[0]\n",
    "print(\"7. Average CV training score: \", mean_train_score)\n",
    "std_train_score = result.std_train_score.values[0]\n",
    "print(\"8. Standard Deviation of CV training score: \", std_train_score)\n",
    "\n",
    "print(\"1st fold validation score: \", result.split0_test_score.values[0])\n",
    "print(\"2nd fold validation score: \", result.split1_test_score.values[0])\n",
    "print(\"3rd fold validation score: \", result.split2_test_score.values[0])\n",
    "print(\"4th fold validation score: \", result.split3_test_score.values[0])\n",
    "print(\"5th fold validation score: \", result.split4_test_score.values[0])\n",
    "print(\"1st fold training score: \", result.split0_train_score.values[0])\n",
    "print(\"2nd fold training score: \", result.split1_train_score.values[0])\n",
    "print(\"3rd fold training score: \", result.split2_train_score.values[0])\n",
    "print(\"4th fold training score: \", result.split3_train_score.values[0])\n",
    "print(\"5th fold training score: \", result.split4_train_score.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.process_time()\n",
    "\n",
    "niter, verbose, random_state = [5, 0, 123] \n",
    "param_space = {'n_neighbors': range(1,20)}\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "cv_clf = RandomizedSearchCV(clf, param_space, cv=kf, n_iter=niter, scoring='roc_auc', return_train_score=True, \n",
    "                            verbose=verbose, n_jobs = -1)\n",
    "cv_clf.fit(X_train_new_x, y_train_new)\n",
    "\n",
    "print('completed in {} s'.format(time.process_time() - start))\n",
    "\n",
    "# write out results\n",
    "model_log(cv_clf, 'knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Five candidate parameters are:  [{'n_neighbors': 7}, {'n_neighbors': 9}, {'n_neighbors': 18}, {'n_neighbors': 1}, {'n_neighbors': 10}]\n",
      "2. Best number of neighbors is: 18\n",
      "3. Best average CV validation score is:  0.5860421015466559\n",
      "4. Standard Deviation of Best average CV validation score is:  0.005290393187255072\n",
      "5. Average CV validation score:  [0.56435268 0.56938242 0.5860421  0.52727264 0.57399634]\n",
      "6. Standard Deviation of CV validation score:  [0.00527947 0.00477997 0.00529039 0.0020675  0.0059998 ]\n",
      "7. Average CV training score:  [0.74477514 0.72450065 0.68253512 1.         0.71711453]\n",
      "8. Standard Deviation of CV training score:  [0.00059892 0.00086726 0.00100905 0.         0.00084448]\n",
      "1st fold validation score:  [0.57242651 0.57436509 0.5901431  0.52323235 0.58135607]\n",
      "2nd fold validation score:  [0.55632186 0.56359608 0.57942082 0.52851801 0.56761344]\n",
      "3rd fold validation score:  [0.56378392 0.56562997 0.58420869 0.52743362 0.56803958]\n",
      "4th fold validation score:  [0.5667624  0.57562715 0.59398254 0.52862411 0.5807987 ]\n",
      "5th fold validation score:  [0.56246848 0.56769361 0.58245491 0.52855528 0.57217367]\n",
      "1st fold training score:  [0.74437361 0.72355538 0.68231841 1.         0.71615291]\n",
      "2nd fold training score:  [0.74584423 0.72457451 0.6829822  1.         0.71687532]\n",
      "3rd fold training score:  [0.74479822 0.72606043 0.68309004 1.         0.71851946]\n",
      "4th fold training score:  [0.7447836  0.72384668 0.68068853 1.         0.7175552 ]\n",
      "5th fold training score:  [0.74407603 0.72446626 0.68359639 1.         0.71646974]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "result = pd.read_csv('knn_cv_rlt.csv')\n",
    "candidate_params = ast.literal_eval(result.candidate_params.values[0])\n",
    "print(\"1. Five candidate parameters are: \", candidate_params)\n",
    "best_k = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['n_neighbors']\n",
    "print(\"2. Best number of neighbors is: {}\".format(best_k))\n",
    "best_score = result.best_score_.values[0]\n",
    "print(\"3. Best average CV validation score is: \", best_score)\n",
    "std_of_best_score = result.std_of_best_mean_test_score.values[0]\n",
    "print(\"4. Standard Deviation of Best average CV validation score is: \", std_of_best_score)\n",
    "mean_test_score = result.mean_test_score.values[0]\n",
    "print(\"5. Average CV validation score: \", mean_test_score)\n",
    "std_test_score = result.std_test_score.values[0]\n",
    "print(\"6. Standard Deviation of CV validation score: \", std_test_score)\n",
    "mean_train_score = result.mean_train_score.values[0]\n",
    "print(\"7. Average CV training score: \", mean_train_score)\n",
    "std_train_score = result.std_train_score.values[0]\n",
    "print(\"8. Standard Deviation of CV training score: \", std_train_score)\n",
    "\n",
    "print(\"1st fold validation score: \", result.split0_test_score.values[0])\n",
    "print(\"2nd fold validation score: \", result.split1_test_score.values[0])\n",
    "print(\"3rd fold validation score: \", result.split2_test_score.values[0])\n",
    "print(\"4th fold validation score: \", result.split3_test_score.values[0])\n",
    "print(\"5th fold validation score: \", result.split4_test_score.values[0])\n",
    "print(\"1st fold training score: \", result.split0_train_score.values[0])\n",
    "print(\"2nd fold training score: \", result.split1_train_score.values[0])\n",
    "print(\"3rd fold training score: \", result.split2_train_score.values[0])\n",
    "print(\"4th fold training score: \", result.split3_train_score.values[0])\n",
    "print(\"5th fold training score: \", result.split4_train_score.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train_new_x)\n",
    "X_train_new = scaling.transform(X_train_new_x)\n",
    "X_test_new = scaling.transform(X_test)\n",
    "X_train_new = pd.DataFrame(X_train_new)\n",
    "X_train_new.columns = X_train_new_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.process_time()\n",
    "\n",
    "#param_space = {'C': [10], 'kernel': ['rbf'], 'gamma': [0.001]}\n",
    "Kfold, niter, verbose, random_state = [2, 2, 10, 1234] \n",
    "param_space = {'C': range(1,101), 'kernel': ['linear','rbf','poly'], 'gamma': [0.001, 0.0001]}\n",
    "\n",
    "clf = svm.SVC(random_state=random_state)\n",
    "cv_clf = RandomizedSearchCV(clf, param_space, cv=Kfold, n_iter=niter, scoring='roc_auc', return_train_score=True, \n",
    "                            verbose=verbose, n_jobs = -1) \n",
    "cv_clf.fit(X_train_new.values, y_train_new.values)\n",
    "\n",
    "print('completed in {} s'.format(time.process_time() - start))\n",
    "\n",
    "# write out results\n",
    "rlt_dict = {}\n",
    "rlt_dict['best_estimator_'] = [cv_clf.best_estimator_]\n",
    "rlt_dict['best_params_'] = [cv_clf.best_params_]\n",
    "rlt_dict['best_score_'] = [cv_clf.best_score_]\n",
    "rlt_dict['best_index_'] = [cv_clf.best_index_]\n",
    "rlt_dict['candidate_params'] = [cv_clf.cv_results_['params']]\n",
    "rlt_dict['mean_test_score'] = [cv_clf.cv_results_['mean_test_score']]\n",
    "rlt_dict['std_test_score'] = [cv_clf.cv_results_['std_test_score']]\n",
    "rlt_dict['mean_train_score'] = [cv_clf.cv_results_['mean_train_score']]\n",
    "rlt_dict['std_train_score'] = [cv_clf.cv_results_['std_train_score']]\n",
    "\n",
    "rlt_dict['split0_test_score'] = [cv_clf.cv_results_['split0_test_score']]\n",
    "rlt_dict['split1_test_score'] = [cv_clf.cv_results_['split1_test_score']]\n",
    "\n",
    "rlt_dict['split0_train_score'] = [cv_clf.cv_results_['split0_train_score']]\n",
    "rlt_dict['split1_train_score'] = [cv_clf.cv_results_['split1_train_score']]\n",
    "\n",
    "rlt_dict['std_of_best_mean_test_score'] = [cv_clf.cv_results_['std_test_score'][max(enumerate(cv_clf.cv_results_['mean_test_score']),key=(lambda x: x[1]))[0]]]\n",
    "\n",
    "rlt_df = pd.DataFrame.from_dict(rlt_dict)\n",
    "rlt_df.to_csv('kernelsvm_cv_rlt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Two candidate parameters are:  [{'kernel': 'rbf', 'gamma': 0.001, 'C': 87}, {'kernel': 'poly', 'gamma': 0.001, 'C': 87}]\n",
      "2. Best C, kernel and gamma are: 87, poly and 0.001\n",
      "3. Best average CV validation score is:  0.7565343438326259\n",
      "4. Standard Deviation of Best average CV validation score is:  0.0013193399255403296\n",
      "5. Average CV validation score:  [0.75568958 0.75653434]\n",
      "6. Standard Deviation of CV validation score:  [0.00101853 0.00131934]\n",
      "7. Average CV training score:  [0.81502068 0.79615193]\n",
      "8. Standard Deviation of CV training score:  [0.00039024 0.00034963]\n",
      "1st fold validation score:  [0.75467108 0.75521504]\n",
      "2nd fold validation score:  [0.75670814 0.75785372]\n",
      "1st fold training score:  [0.81541093 0.79650157]\n",
      "2nd fold training score:  [0.81463044 0.7958023 ]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "result = pd.read_csv('kernelsvm_cv_rlt.csv')\n",
    "candidate_params = ast.literal_eval(result.candidate_params.values[0])\n",
    "print(\"1. Two candidate parameters are: \", candidate_params)\n",
    "best_c = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['C']\n",
    "best_kernel = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['kernel']\n",
    "best_gamma = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['gamma']\n",
    "print(\"2. Best C, kernel and gamma are: {}, {} and {}\".format(best_c, best_kernel, best_gamma))\n",
    "best_score = result.best_score_.values[0]\n",
    "print(\"3. Best average CV validation score is: \", best_score)\n",
    "std_of_best_score = result.std_of_best_mean_test_score.values[0]\n",
    "print(\"4. Standard Deviation of Best average CV validation score is: \", std_of_best_score)\n",
    "mean_test_score = result.mean_test_score.values[0]\n",
    "print(\"5. Average CV validation score: \", mean_test_score)\n",
    "std_test_score = result.std_test_score.values[0]\n",
    "print(\"6. Standard Deviation of CV validation score: \", std_test_score)\n",
    "mean_train_score = result.mean_train_score.values[0]\n",
    "print(\"7. Average CV training score: \", mean_train_score)\n",
    "std_train_score = result.std_train_score.values[0]\n",
    "print(\"8. Standard Deviation of CV training score: \", std_train_score)\n",
    "\n",
    "print(\"1st fold validation score: \", result.split0_test_score.values[0])\n",
    "print(\"2nd fold validation score: \", result.split1_test_score.values[0])\n",
    "print(\"1st fold training score: \", result.split0_train_score.values[0])\n",
    "print(\"2nd fold training score: \", result.split1_train_score.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the final model which has the highest average cross validation AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross Validation AUC for RandomForest, XGboost, LogReg, LightGBM, KNN, SVM are: 0.7500, 0.7722, 0.7704, 0.7652, 0.5860, 0.7565\n",
      "Standard Deviation of Average Cross Validation AUC for RandomForest, XGboost, LogReg, LightGBM, KNN, SVM are: 0.0076, 0.0074, 0.0065, 0.0040, 0.0053, 0.0013\n",
      "Best model is:  XGboost\n"
     ]
    }
   ],
   "source": [
    "def read_cv_results(filename):\n",
    "    result = pd.read_csv(filename)\n",
    "    best_score = result.best_score_.values[0]\n",
    "    std_score = result.std_of_best_mean_test_score.values[0]\n",
    "    return [best_score, std_score]\n",
    "\n",
    "cv_RFT = read_cv_results('randomforest_cv_rlt.csv')[0]\n",
    "cv_XGB = read_cv_results('xgboost_cv_rlt.csv')[0]\n",
    "cv_LGB = read_cv_results('lightgbm_cv_rlt.csv')[0]\n",
    "cv_LGI = read_cv_results('logistic_cv_rlt.csv')[0]\n",
    "cv_KNN = read_cv_results('knn_cv_rlt.csv')[0]\n",
    "cv_SVM = read_cv_results('kernelsvm_cv_rlt.csv')[0]  \n",
    "\n",
    "std_cv_RFT = read_cv_results('randomforest_cv_rlt.csv')[1]\n",
    "std_cv_XGB = read_cv_results('xgboost_cv_rlt.csv')[1]\n",
    "std_cv_LGB = read_cv_results('lightgbm_cv_rlt.csv')[1]\n",
    "std_cv_LGI = read_cv_results('logistic_cv_rlt.csv')[1]\n",
    "std_cv_KNN = read_cv_results('knn_cv_rlt.csv')[1]\n",
    "std_cv_SVM = read_cv_results('kernelsvm_cv_rlt.csv')[1] \n",
    "\n",
    "print(f\"Average Cross Validation AUC for RandomForest, XGboost, LogReg, LightGBM, KNN, SVM are: {cv_RFT:.4f}, {cv_XGB:.4f}, {cv_LGB:.4f}, {cv_LGI:.4f}, {cv_KNN:.4f}, {cv_SVM:.4f}\")\n",
    "print(f\"Standard Deviation of Average Cross Validation AUC for RandomForest, XGboost, LogReg, LightGBM, KNN, SVM are: {std_cv_RFT:.4f}, {std_cv_XGB:.4f}, {std_cv_LGB:.4f}, {std_cv_LGI:.4f}, {std_cv_KNN:.4f}, {std_cv_SVM:.4f}\")\n",
    "\n",
    "all_scores = [cv_RFT, cv_XGB, cv_LGB, cv_LGI, cv_KNN, cv_SVM]\n",
    "modelnames = ['RandomForest','XGboost','LightGBM','Logistic','KNN','SVM']\n",
    "print(\"Best model is: \", modelnames[max(enumerate(all_scores),key=(lambda x: x[1]))[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
